{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b7dbbb-d2d2-475d-a9ba-146b0f1b5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "#!pip install yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47649a5-dc1b-41bf-be54-62a5ced3c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72635459-0eca-4a74-a2b0-7f76bc5ae301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:49 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# SparkSession başlatma\n",
    "spark = SparkSession.builder.appName(\"NVDA Price Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb55655-8673-4950-9282-cac36c8dce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükleme ve DataFrame oluşturma\n",
    "df = spark.read.csv(\"file:///home/hduser/Desktop/NVDA/NVDA_histrical_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# 'Date' sütununu tarih tipine dönüştürme (gerekirse)\n",
    "df = df.withColumn(\"Date\", to_date(df[\"Date\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f91e3d-3dd6-409e-8690-b9ca2aed1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60a8965-20f2-434d-af31-490396106316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+------------------+--------+\n",
      "|      Date|              Open|              High|               Low|             Close|         Adj Close|  Volume|\n",
      "+----------+------------------+------------------+------------------+------------------+------------------+--------+\n",
      "|2023-03-15|237.61000061035156|242.86000061035156|233.60000610351562|242.27999877929688|242.20230102539062|52448600|\n",
      "|2023-03-16|240.27000427246094| 255.8800048828125|238.94000244140625|255.41000366210938|255.32810974121094|58325300|\n",
      "|2023-03-17|259.82000732421875|  263.989990234375|256.67999267578125|            257.25|257.16754150390625|84854700|\n",
      "|2023-03-20| 256.1499938964844|  260.239990234375| 251.3000030517578|             259.0| 258.9169616699219|43274700|\n",
      "|2023-03-21|261.79998779296875| 263.9200134277344|253.80999755859375|  261.989990234375| 261.9059753417969|54740800|\n",
      "+----------+------------------+------------------+------------------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(df.tail(5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996c94f4-88cd-4e1f-b3a7-556afd25a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+---+-----+---------+------+\n",
      "|Date|Open|High|Low|Close|Adj Close|Volume|\n",
      "+----+----+----+---+-----+---------+------+\n",
      "|   0|   0|   0|  0|    0|        0|     0|\n",
      "+----+----+----+---+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "# Her bir sütun için eksik değer sayısını hesaplama\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b398c059-d971-42fc-92e8-9167fb874f3c",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import lit, percentile_approx\n",
    "\n",
    "# IQR - Interquartile Range hesaplayarak aykırı değerleri bulma\n",
    "bounds = {\n",
    "    c: dict(\n",
    "        zip([\"q1\", \"q3\"], df.approxQuantile(c, [0.25, 0.75], 0))\n",
    "    )\n",
    "    for c in ['Close'] # Aykırı değer kontrolü yapılacak sütunlar\n",
    "}\n",
    "\n",
    "for c in bounds:\n",
    "    iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "    bounds[c]['min'] = bounds[c]['q1'] - (1.5 * iqr)\n",
    "    bounds[c]['max'] = bounds[c]['q3'] + (1.5 * iqr)\n",
    "\n",
    "# Aykırı değerleri filtreleme\n",
    "outliers = df.select(\n",
    "    '*',\n",
    "    *[\n",
    "        when(\n",
    "            (col(c) < bounds[c]['min']) | (col(c) > bounds[c]['max']),\n",
    "            c\n",
    "        ).alias(c + '_outlier') for c in bounds\n",
    "    ]\n",
    ")\n",
    "outliers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0dc0c4-1e41-4ba1-bb15-d04b51bca0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d469b3-e2c9-4a70-8b79-432c82b3f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+--------------------+--------------------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|            features|      scaledFeatures|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+--------------------+--------------------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|[0.44661501049995...|[-0.5119521473795...|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|[0.42708298563957...|[-0.5122838808479...|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400|[0.39583298563957...|[-0.5128146333409...|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|[0.39453101158142...|[-0.5128367461722...|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|[0.40625,0.4375,0...|[-0.5126377099380...|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Özellikleri bir vektör haline getirme\n",
    "assembler = VectorAssembler(inputCols=['Open', 'High', 'Low', 'Volume'], outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "# Ölçeklendirme için StandardScaler kullanma\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(df_assembled)\n",
    "df_scaled = scalerModel.transform(df_assembled)\n",
    "\n",
    "df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733a357-5e10-43fb-b037-da6375a21c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf173c40-10df-48fe-aa43-f622ad264f33",
   "metadata": {},
   "source": [
    "# ozellik muhendisligi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd15df1a-b9fb-4f39-8bdd-b78070dffa7c",
   "metadata": {},
   "source": [
    "# bir gunde birden fazla satir varsa kullanilir. mesela farkli borsalardan alinmis bir hisse senede gibi\n",
    "\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Sütunlarınızın isimlerine göre uyarlamanız gerekebilir.\n",
    "windowSpec = Window.partitionBy('Date').orderBy('Date').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Örneğin, her bir 'GroupingColumn' grubu için 'TargetColumn' üzerinde hareketli ortalama hesaplayalım.\n",
    "df = df.withColumn('MovingAverage', avg('Close').over(windowSpec))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15082aa1-6d33-4091-92f3-ef6b41581c67",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "df = df.withColumn('Year', year(df['Date']))\n",
    "df = df.withColumn('Month', month(df['Date']))\n",
    "df = df.withColumn('Day', dayofmonth(df['Date']))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5081cf-aa43-4ee0-89b3-dc112e04800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|         Prev_Close|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|               null|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|0.42447900772094727|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400| 0.3984380066394806|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|0.39583298563957214|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|0.40104201436042786|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "windowSpec = Window.orderBy('Date')\n",
    "df = df.withColumn('Prev_Close', lag(df['Close']).over(windowSpec))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e314dae-449f-404f-b386-bb29b433ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|         Prev_Close|      Short_Average|       Long_Average|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|               null|0.42447900772094727|0.42447900772094727|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|0.42447900772094727|0.41145850718021393|0.41145850718021393|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400| 0.3984380066394806|            0.40625|            0.40625|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|0.39583298563957214|0.40494800359010696|0.40494800359010696|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|0.40104201436042786|0.41119800209999086|0.41119800209999086|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "short_window = Window.orderBy('Date').rowsBetween(-30, 0)\n",
    "long_window = Window.orderBy('Date').rowsBetween(-90, 0)\n",
    "\n",
    "df = df.withColumn('Short_Average', avg('Close').over(short_window))\n",
    "df = df.withColumn('Long_Average', avg('Close').over(long_window))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b592fc5a-7f4a-4a59-b54f-d3fdb9c60c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|         Prev_Close|      Short_Average|       Long_Average|      Day_Pct_Change|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|               null|0.42447900772094727|0.42447900772094727|                null|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|0.42447900772094727|0.41145850718021393|0.41145850718021393|-0.06134814821887...|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400| 0.3984380066394806|            0.40625|            0.40625|-0.00653808360773...|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|0.39583298563957214|0.40494800359010696|0.40494800359010696| 0.01315966306456032|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|0.40104201436042786|0.41119800209999086|0.41119800209999086|  0.0876615928512239|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn('Day_Pct_Change', (col('Close') - col('Prev_Close')) / col('Prev_Close'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31ddf4b-5550-4712-96d3-bbedcc02b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+------------------+\n",
      "|      Date|               Open|               High|                Low|              Close|          Adj Close|  Volume|         Prev_Close|      Short_Average|       Long_Average|      Day_Pct_Change|        Log_Volume|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+------------------+\n",
      "|1999-03-22| 0.4466150104999542|0.44791701436042786|0.42447900772094727|0.42447900772094727| 0.3893754184246063| 3667200|               null|0.42447900772094727|0.42447900772094727|                null|15.114938986062503|\n",
      "|1999-03-23|0.42708298563957214|0.42708298563957214|           0.390625| 0.3984380066394806|0.36548805236816406|16396800|0.42447900772094727|0.41145850718021393|0.41145850718021393|-0.06134814821887...|16.612596751804443|\n",
      "|1999-03-24|0.39583298563957214| 0.3984380066394806|0.38020798563957214|0.39583298563957214|0.36309847235679626| 6086400| 0.3984380066394806|            0.40625|            0.40625|-0.00653808360773...|15.621567331893154|\n",
      "|1999-03-25| 0.3945310115814209|0.41666701436042786|0.39322900772094727|0.40104201436042786|0.36787667870521545| 4032000|0.39583298563957214|0.40494800359010696|0.40494800359010696| 0.01315966306456032| 15.20977308873334|\n",
      "|1999-03-26|            0.40625|             0.4375|            0.40625|0.43619799613952637| 0.4001253545284271| 8827200|0.40104201436042786|0.41119800209999086|0.41119800209999086|  0.0876615928512239|15.993348421500304|\n",
      "+----------+-------------------+-------------------+-------------------+-------------------+-------------------+--------+-------------------+-------------------+-------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import log\n",
    "\n",
    "df = df.withColumn('Log_Volume', log(col('Volume')))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf34d3-1605-49bb-8090-ad6367611f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359aee9c-bcd7-46ed-ab28-ac0a180a6e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b7b5d-b0f5-4cff-bca5-888b77f7d781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a58ae-044a-44ce-8b94-c819f7dde3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3d7a6-5ce1-43ef-ae56-739bf2407c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19553181-3613-4f53-81df-ae5f90dd9b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c7885-d629-4795-968a-b094ef969e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5234bf-3ad2-445b-afd8-9a8e328e8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying properties and target variable\n",
    "feature_columns = ['Open', 'High', 'Low', 'Volume']  # Örnek özellikler\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10bc78ca-3ebb-49d4-9ed9-4b9f8d66e6da",
   "metadata": {},
   "source": [
    "In this cell, we have selected the features that your machine learning model will use as input and turned them into a vector. The columns 'Open', 'High', 'Low', and 'Volume' are the features that will be used for the model to learn. Using VectorAssembler, we combine these features into a single vector column (in the 'features' column). This is done to meet the requirements of Spark's machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99c252d9-ad38-4435-b525-3d58cd46c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "data = data.withColumn(\"label\", data[\"Close\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e57d807a-285d-4eb5-9d7b-3d33eade8c42",
   "metadata": {},
   "source": [
    "In this cell, we have set the target variable that your model will try to predict. In this case, we have chosen the 'Close' column, i.e. the closing price of the stock, as the target and added it to the DataFrame as the 'label' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e49b86-f9dd-49b8-9310-eb5321c6bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc52e458-3d84-4364-97ef-74b93958cc77",
   "metadata": {},
   "source": [
    "The dataset is split into two parts for training and testing the model. Usually a large part of the dataset (80% in this case) is allocated for training the model and a small part (20% in this case) is allocated for testing the model. The seed parameter ensures that this split is the same each time the model is run, so that the results can be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9e68ccf-376c-4c50-8be9-3f331669f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN Instrumentation: [6b90d7c6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/03/25 12:50:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/03/25 12:50:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# Model creation and training\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label')\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b984945-e44f-42b6-9c77-9ba48dbef67c",
   "metadata": {},
   "source": [
    "In this cell, we created a LinearRegression model and trained it using the training data. After the model was created, we fit it to the training data with the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08337b1-f21b-4884-8a08-297b463feec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6798f2d7-0368-4f74-8886-95daec739a28",
   "metadata": {},
   "source": [
    "With the transform method, we generated a prediction for each row in the test set and added these predictions to the test DataFrame as the 'prediction' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363f57b4-61da-413b-881f-8b0c87524ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 0.8952458650775283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/25 12:50:54 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "# Evaluating performance\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcc978bb-4cca-4a90-a669-6840a4a3cee1",
   "metadata": {},
   "source": [
    "The performance of the model is evaluated using the difference between the actual values and the model's predictions. In this study, we calculate the root mean square error (RMSE) using the RegressionEvaluator class. RMSE is a measure of how accurate the predictions are; the lower the value, the better the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73dd17-9673-46fb-ad0e-501741d39a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bde9ca-9f67-4124-91e5-539950345be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
